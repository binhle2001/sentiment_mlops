{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BAAI/bge-m3 với Dữ liệu Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook này thực hiện quá trình fine-tuning model embedding `BAAI/bge-m3` bằng cách sử dụng bộ dữ liệu triplets (`query`, `positive`, `negative`) đã được tạo từ file `embedding_training_data.jsonl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cài đặt các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tải và chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import InputExample\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Tải dữ liệu từ file jsonl\n",
    "data_file = 'embedding_training_data.jsonl'\n",
    "dataset = load_dataset('json', data_files=data_file, split='train')\n",
    "\n",
    "print(f\"Đã tải {len(dataset)} mẫu training.\")\n",
    "print(\"Ví dụ một mẫu:\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, chúng ta cần chuyển đổi dữ liệu thành định dạng `InputExample` mà `sentence-transformers` có thể sử dụng. Đối với `MultipleNegativesRankingLoss`, mỗi `InputExample` sẽ chứa một bộ ba `[query, positive_passage, negative_passage]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "for item in tqdm(dataset, desc=\"Chuẩn bị dữ liệu\"):\n",
    "    train_examples.append(InputExample(texts=[item['query'], item['pos'], item['neg']]))\n",
    "\n",
    "print(f\"\\nĐã tạo {len(train_examples)} InputExample.\")\n",
    "print(\"Ví dụ một InputExample:\")\n",
    "print(train_examples[0].texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Khởi tạo Model và DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý lỗi không tải được model (Quan trọng)\n",
    "\n",
    "Lỗi `Can't load the model for 'BAAI/bge-m3'` thường xảy ra do vấn đề về mạng (ví dụ: firewall, proxy trong môi trường công ty) ngăn cản việc tải model trực tiếp từ Hugging Face Hub.\n",
    "\n",
    "**Giải pháp:** Tải model về máy thủ công và load từ đường dẫn cục bộ.\n",
    "\n",
    "1.  **Tải model:** Mở terminal và chạy lệnh sau để tải model vào một thư mục có tên `bge-m3-model`:\n",
    "    ```bash\n",
    "    git lfs install\n",
    "    git clone https://huggingface.co/BAAI/bge-m3 bge-m3-model\n",
    "    ```\n",
    "    *Lưu ý: Bạn cần cài đặt [Git LFS](https://git-lfs.com) để tải các file model lớn.*\n",
    "\n",
    "2.  **Chạy cell dưới đây:** Code đã được sửa để load model từ thư mục `bge-m3-model` bạn vừa tải về."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Đường dẫn đến thư mục model đã tải về\n",
    "# LƯU Ý: Hãy chắc chắn rằng bạn đã chạy lệnh git clone ở trên\n",
    "# và có một thư mục tên là 'bge-m3-model' trong cùng thư mục với notebook này.\n",
    "model_name = './bge-m3-model'\n",
    "\n",
    "# Tải model từ đường dẫn cục bộ\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "print(\"Đã tải xong model BAAI/bge-m3 từ đường dẫn cục bộ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Định nghĩa Loss Function và Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo DataLoader\n",
    "train_batch_size = 16 # Điều chỉnh tùy theo VRAM của bạn\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "# Sử dụng MultipleNegativesRankingLoss, đây là loss function tiêu chuẩn cho dữ liệu triplets\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "# Các tham số training\n",
    "num_epochs = 1\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) # 10% of train data for warm-up\n",
    "output_path = './bge-m3-fine-tuned-feedback'\n",
    "\n",
    "print(\"Bắt đầu quá trình training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển sang Vòng lặp Training Thủ công (Để kiểm soát VRAM)\n",
    "\n",
    "Hàm `model.fit()` rất tiện lợi, nhưng đôi khi có thể gây ra hiện tượng tăng VRAM không kiểm soát (memory leak) trong các phiên training dài. Để khắc phục, chúng ta sẽ tự viết một vòng lặp training thủ công. Cách này cho phép chúng ta kiểm soát hoàn toàn quá trình và đảm bảo bộ nhớ được giải phóng đúng cách sau mỗi bước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import trange\n",
    "import torch\n",
    "\n",
    "# Định nghĩa optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Bắt đầu training trên thiết bị: {device}\")\n",
    "\n",
    "for epoch in trange(num_epochs, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=\"Iteration\", smoothing=0.05)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Chuyển batch sang đúng device\n",
    "        features, labels = model.batch_to_device(batch, device)\n",
    "        \n",
    "        # Tính loss\n",
    "        loss = train_loss(features, labels)\n",
    "        \n",
    "        # Lan truyền ngược và cập nhật trọng số\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Lấy giá trị loss (dạng số) để theo dõi, tránh memory leak\n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "        \n",
    "        progress_bar.set_description(f\"Loss: {current_loss:.4f}\")\n",
    "        \n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "print(\"Training hoàn tất.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu lại model đã fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(output_path)\n",
    "print(f\"Model đã được lưu tại: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hoàn tất\n",
    "\n",
    "Quá trình training đã hoàn tất. Model đã được fine-tuned và lưu tại thư mục `bge-m3-fine-tuned-feedback`. Bạn có thể tải và sử dụng model này như một model `sentence-transformer` thông thường."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Đánh giá & Kiểm thử Model (Evaluation & Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, hãy thử sử dụng model vừa fine-tuned để xem nó hoạt động như thế nào với một feedback mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# Tải model đã fine-tuned\n",
    "model = SentenceTransformer(output_path)\n",
    "\n",
    "# Chuẩn bị kho nhãn (corpus) để tìm kiếm\n",
    "# Chúng ta sẽ lấy tất cả các nhãn duy nhất từ bộ dữ liệu\n",
    "all_labels = list(set([item['pos'] for item in dataset] + [item['neg'] for item in dataset]))\n",
    "\n",
    "print(f\"Đã tạo kho với {len(all_labels)} nhãn duy nhất.\")\n",
    "\n",
    "# Mã hóa toàn bộ kho nhãn. Chuyển sang GPU nếu có thể.\n",
    "print(\"Đang mã hóa kho nhãn...\")\n",
    "corpus_embeddings = model.encode(all_labels, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "print(\"Mã hóa hoàn tất.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback mẫu để kiểm thử\n",
    "test_query = \"App ngân hàng cứ bị văng ra lúc đang chuyển tiền, rất bực mình. Lãi suất gửi tiết kiệm cũng thấp quá.\"\n",
    "\n",
    "# Mã hóa feedback\n",
    "query_embedding = model.encode(test_query, convert_to_tensor=True)\n",
    "\n",
    "# Sử dụng semantic search để tìm top 5 nhãn tương đồng nhất\n",
    "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "hits = hits[0] # Lấy kết quả cho query đầu tiên\n",
    "\n",
    "print(f\"Feedback mẫu: '{test_query}'\\n\")\n",
    "print(\"Top 5 nhãn phù hợp nhất:\")\n",
    "for hit in hits:\n",
    "    print(f\"\\t{all_labels[hit['corpus_id']]:<40} (Score: {hit['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Đóng gói để Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để tiện sử dụng, chúng ta có thể tạo một lớp đơn giản để đóng gói logic này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackClassifier:\n",
    "    def __init__(self, model_path, all_labels):\n",
    "        self.model = SentenceTransformer(model_path)\n",
    "        self.labels = all_labels\n",
    "        print(\"Đang mã hóa kho nhãn cho classifier...\")\n",
    "        self.label_embeddings = self.model.encode(self.labels, convert_to_tensor=True, show_progress_bar=True)\n",
    "        print(\"Classifier sẵn sàng.\")\n",
    "        \n",
    "    def predict(self, feedback_text, top_k=3):\n",
    "        query_embedding = self.model.encode(feedback_text, convert_to_tensor=True)\n",
    "        hits = util.semantic_search(query_embedding, self.label_embeddings, top_k=top_k)\n",
    "        results = []\n",
    "        for hit in hits[0]:\n",
    "            results.append({\n",
    "                'label': self.labels[hit['corpus_id']],\n",
    "                'score': hit['score']\n",
    "            })\n",
    "        return results\n",
    "\n",
    "# Khởi tạo classifier\n",
    "classifier = FeedbackClassifier(model_path=output_path, all_labels=all_labels)\n",
    "\n",
    "# Sử dụng classifier\n",
    "new_feedback = \"Nhân viên tại quầy giao dịch rất nhiệt tình và chuyên nghiệp, nhưng thủ tục mở thẻ tín dụng còn rườm rà.\"\n",
    "predictions = classifier.predict(new_feedback, top_k=3)\n",
    "\n",
    "print(f\"\\nFeedback: '{new_feedback}'\")\n",
    "print(\"Dự đoán:\")\n",
    "for pred in predictions:\n",
    "    print(f\"- {pred['label']} (Score: {pred['score']:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
