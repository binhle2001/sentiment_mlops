"""API routes for label management."""
import asyncio
import csv
import json
import logging
import os
from datetime import datetime
from io import BytesIO
from pathlib import Path
from typing import Optional, List, Dict, Any
from uuid import UUID, uuid4

import httpx
from fastapi import APIRouter, Depends, HTTPException, Query, status, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse

from openpyxl import load_workbook

from database import get_db
from crud import LabelCRUD, FeedbackSentimentCRUD, FeedbackIntentCRUD
from gemini_service import get_gemini_service
from schemas import (
    LabelCreate,
    LabelUpdate,
    LabelResponse,
    LabelTreeResponse,
    LabelListResponse,
    HealthResponse,
    BulkLabelCreate,
    BulkLabelResponse,
    FeedbackSentimentCreate,
    FeedbackSentimentUpdate,
    FeedbackSentimentResponse,
    FeedbackSentimentListResponse,
    FeedbackSource,
    SentimentLabel,
    IntentTriplet,
    FeedbackIntentResponse,
    LabelSyncItem,
    LabelSyncRequest,
    LabelSyncResponse,
    FeedbackReprocessStatus,
    FeedbackImportResponse,
)
from config import get_settings
from training_manager import get_training_manager
from training_log import is_training_in_progress

logger = logging.getLogger(__name__)
settings = get_settings()

router = APIRouter()


@router.get("/health", response_model=HealthResponse, summary="Health check endpoint")
def health_check():
    """Health check endpoint."""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.utcnow(),
        database="ok",
        version=settings.app_version
    )


@router.get(
    "/training/status",
    summary="Kiá»ƒm tra tráº¡ng thÃ¡i trigger huáº¥n luyá»‡n"
)
async def training_status():
    """Kiá»ƒm tra tráº¡ng thÃ¡i training cá»§a sentiment vÃ  embedding services."""
    try:
        manager = get_training_manager()
    except RuntimeError:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Training manager chÆ°a Ä‘Æ°á»£c khá»Ÿi táº¡o"
        )
    
    # Kiá»ƒm tra tráº¡ng thÃ¡i training
    sentiment_training = is_training_in_progress("sentiment")
    embedding_training = is_training_in_progress("embedding")
    
    status_info = {
        "sentiment": {
            "is_training": sentiment_training,
            "message": "ðŸ”„ Äang training sentiment model" if sentiment_training else "âœ… Sentiment model sáºµn sÃ ng"
        },
        "embedding": {
            "is_training": embedding_training,
            "message": "ðŸ”„ Äang training embedding model" if embedding_training else "âœ… Embedding model sáºµn sÃ ng"
        },
        "warning": None
    }
    
    # ThÃªm cáº£nh bÃ¡o náº¿u cáº£ hai Ä‘ang training
    if sentiment_training and embedding_training:
        status_info["warning"] = "âš ï¸  Cáº£ sentiment vÃ  embedding Ä‘ang training - cÃ¡c service cÃ³ thá»ƒ bá»‹ cháº­m"
    elif sentiment_training:
        status_info["warning"] = "âš ï¸  Äang training sentiment - embedding service cÃ³ thá»ƒ bá»‹ cháº­m"
    elif embedding_training:
        status_info["warning"] = "âš ï¸  Äang training embedding - sentiment service cÃ³ thá»ƒ bá»‹ cháº­m"
    
    return status_info


@router.post(
    "/labels",
    response_model=LabelResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Create a new label"
)
async def create_label(label_data: LabelCreate, background_tasks: BackgroundTasks):
    """Create a new label in the hierarchy."""
    try:
        with get_db() as conn:
            # Check if label with same name and parent already exists
            exists = LabelCRUD.exists_by_name_and_parent(
                conn, label_data.name, label_data.parent_id
            )
            if exists:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"Label '{label_data.name}' already exists under this parent"
                )
            
            label = LabelCRUD.create(conn, label_data)

            # Trigger training check in the background if enabled
            if settings.enable_training_trigger:
                background_tasks.add_task(trigger_training_on_new_label)

            return label
    except HTTPException:
        raise
    except ValueError as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(e))
    except Exception as e:
        logger.error(f"Error creating label: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to create label"
        )

async def trigger_training_on_new_label():
    """Background task to trigger training check after a new label is created."""
    try:
        manager = await get_training_manager()
        await manager.check_and_trigger_all(triggered_by='new_label')
    except Exception as e:
        logger.error(f"Failed to trigger training on new label: {e}", exc_info=True)


@router.post(
    "/labels/bulk",
    response_model=BulkLabelResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Create multiple labels at once"
)
def create_labels_bulk(bulk_data: BulkLabelCreate):
    """Create multiple labels in a single request.
    
    This endpoint allows you to create multiple labels at once.
    Each label is validated and created independently.
    If some labels fail, others will still be created successfully.
    """
    try:
        with get_db() as conn:
            results = LabelCRUD.bulk_create(conn, bulk_data.labels)
            
            # Count successes and failures
            successful = sum(1 for r in results if r['success'])
            failed = sum(1 for r in results if not r['success'])
            
            return BulkLabelResponse(
                total=len(bulk_data.labels),
                successful=successful,
                failed=failed,
                results=results
            )
    except Exception as e:
        logger.error(f"Error in bulk label creation: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to process bulk label creation"
        )


@router.get(
    "/labels/export",
    summary="Export all labels as JSON backup"
)
def export_labels_backup():
    """Export táº¥t cáº£ labels ra file JSON Ä‘á»ƒ backup."""
    try:
        with get_db() as conn:
            # Láº¥y táº¥t cáº£ labels khÃ´ng giá»›i háº¡n
            labels = LabelCRUD.get_all(conn, skip=0, limit=100000)
            
            # Chuyá»ƒn Ä‘á»•i sang format LabelSyncItem (cÃ³ id, name, level, parent_id, description, updated_at)
            export_data = {
                "labels": [
                    {
                        "id": label["id"],
                        "name": label["name"],
                        "level": label["level"],
                        "parent_id": label.get("parent_id"),
                        "description": label.get("description"),
                        "updated_at": label.get("updated_at").isoformat() if label.get("updated_at") else None
                    }
                    for label in labels
                ],
                "exported_at": datetime.utcnow().isoformat(),
                "total": len(labels)
            }
            
            return JSONResponse(
                content=export_data,
                headers={
                    "Content-Disposition": f"attachment; filename=labels_backup_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
                }
            )
    except Exception as e:
        logger.error(f"Error exporting labels: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to export labels"
        )


@router.post(
    "/labels/sync",
    response_model=LabelSyncResponse,
    summary="Sync labels from external system (JSON file or JSON body)"
)
async def sync_labels(
    sync_request: Optional[LabelSyncRequest] = None,
    file: Optional[UploadFile] = File(None)
):
    """Äá»“ng bá»™ label tá»« há»‡ thá»‘ng ngoÃ i vÃ  xá»­ lÃ½ feedback bá»‹ áº£nh hÆ°á»Ÿng.
    
    CÃ³ thá»ƒ nháº­n dá»¯ liá»‡u tá»«:
    - File JSON upload (file parameter)
    - JSON body (sync_request parameter)
    """
    impacted_feedback_ids: List[UUID] = []
    labels_to_sync = []

    try:
        # Náº¿u cÃ³ file upload, Ä‘á»c tá»« file
        if file:
            if not file.filename or not file.filename.lower().endswith('.json'):
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Chá»‰ há»— trá»£ file JSON"
                )
            content = await file.read()
            try:
                data = json.loads(content.decode('utf-8'))
                # Há»— trá»£ cáº£ format cÃ³ "labels" key hoáº·c trá»±c tiáº¿p lÃ  array
                if isinstance(data, dict) and "labels" in data:
                    labels_data = data["labels"]
                elif isinstance(data, list):
                    labels_data = data
                else:
                    raise HTTPException(
                        status_code=status.HTTP_400_BAD_REQUEST,
                        detail="File JSON khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng. Cáº§n cÃ³ key 'labels' hoáº·c lÃ  array"
                    )
                
                # Chuyá»ƒn Ä‘á»•i dicts thÃ nh LabelSyncItem objects
                labels_to_sync = []
                for label_dict in labels_data:
                    try:
                        # Parse updated_at náº¿u cÃ³ (cÃ³ thá»ƒ lÃ  string ISO format)
                        if "updated_at" in label_dict and label_dict["updated_at"]:
                            if isinstance(label_dict["updated_at"], str):
                                try:
                                    label_dict["updated_at"] = datetime.fromisoformat(label_dict["updated_at"].replace('Z', '+00:00'))
                                except ValueError:
                                    # Fallback náº¿u format khÃ´ng Ä‘Ãºng
                                    label_dict["updated_at"] = None
                        label_item = LabelSyncItem(**label_dict)
                        labels_to_sync.append(label_item)
                    except Exception as e:
                        raise HTTPException(
                            status_code=status.HTTP_400_BAD_REQUEST,
                            detail=f"Label khÃ´ng há»£p lá»‡: {label_dict.get('id', 'unknown')} - {str(e)}"
                        )
            except json.JSONDecodeError as e:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=f"File JSON khÃ´ng há»£p lá»‡: {str(e)}"
                )
        elif sync_request:
            # Náº¿u cÃ³ sync_request tá»« body
            labels_to_sync = sync_request.labels
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Cáº§n cung cáº¥p file JSON hoáº·c JSON body"
            )
        
        if not labels_to_sync:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="KhÃ´ng cÃ³ label nÃ o Ä‘á»ƒ sync"
            )

        with get_db() as conn:
            sync_result = LabelCRUD.sync_labels(conn, labels_to_sync)
            changed_label_ids = sync_result.get("changed_label_ids", [])

            if changed_label_ids:
                impacted_feedback_ids = FeedbackSentimentCRUD.reset_feedback_for_labels(
                    conn,
                    changed_label_ids,
                )
                if impacted_feedback_ids:
                    FeedbackIntentCRUD.delete_by_feedback_ids(conn, impacted_feedback_ids)
    except ValueError as exc:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(exc)
        )
    except HTTPException:
        raise
    except Exception as exc:
        logger.error("Error syncing labels: %s", exc, exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to sync labels"
        )

    reprocess_results = await _reprocess_feedbacks_after_label_update(impacted_feedback_ids)

    return LabelSyncResponse(
        created=sync_result["created"],
        updated=sync_result["updated"],
        unchanged=sync_result["unchanged"],
        results=sync_result["results"],
        total=len(labels_to_sync),
        changed_label_ids=sync_result.get("changed_label_ids", []),
        impacted_feedbacks=len(impacted_feedback_ids),
        reprocessed_feedbacks=reprocess_results,
    )


@router.get(
    "/labels",
    response_model=LabelListResponse,
    summary="Get all labels with optional filters"
)
def get_labels(
    level: Optional[int] = Query(None, ge=1, le=3, description="Filter by level"),
    parent_id: Optional[int] = Query(None, ge=1, description="Filter by parent ID"),
    skip: int = Query(0, ge=0, description="Number of records to skip"),
    limit: int = Query(100, ge=1, le=1000, description="Maximum number of records"),
):
    """Get all labels with optional filters."""
    try:
        with get_db() as conn:
            labels = LabelCRUD.get_all(conn, level=level, parent_id=parent_id, skip=skip, limit=limit)
            total = LabelCRUD.count(conn, level=level, parent_id=parent_id)
            
            return LabelListResponse(
                labels=labels,
                total=total,
                level=level,
                parent_id=parent_id
            )
    except Exception as e:
        logger.error(f"Error getting labels: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve labels"
        )


@router.get(
    "/labels/tree",
    response_model=list[LabelTreeResponse],
    summary="Get full label hierarchy as tree"
)
def get_label_tree():
    """Get the full label hierarchy as a tree structure."""
    try:
        with get_db() as conn:
            tree = LabelCRUD.get_tree(conn)
            return tree
    except Exception as e:
        logger.error(f"Error getting label tree: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve label tree"
        )


@router.get(
    "/labels/{label_id}",
    response_model=LabelResponse,
    summary="Get label by ID"
)
def get_label(label_id: int):
    """Get a specific label by ID."""
    try:
        with get_db() as conn:
            label = LabelCRUD.get_by_id(conn, label_id)
            if not label:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Label with id {label_id} not found"
                )
            return label
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting label {label_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve label"
        )


@router.get(
    "/labels/{label_id}/children",
    response_model=list[LabelResponse],
    summary="Get children of a label"
)
def get_label_children(label_id: int):
    """Get all children of a specific label."""
    try:
        with get_db() as conn:
            # First check if parent exists
            parent = LabelCRUD.get_by_id(conn, label_id)
            if not parent:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Label with id {label_id} not found"
                )
            
            children = LabelCRUD.get_children(conn, label_id)
            return children
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting children for label {label_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve label children"
        )


@router.put(
    "/labels/{label_id}",
    response_model=LabelResponse,
    summary="Update a label"
)
def update_label(
    label_id: int,
    label_data: LabelUpdate,
):
    """Update a label's name or description."""
    try:
        with get_db() as conn:
            label = LabelCRUD.update(conn, label_id, label_data)
            if not label:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Label with id {label_id} not found"
                )
            return label
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating label {label_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to update label"
        )


@router.delete(
    "/labels/{label_id}",
    status_code=status.HTTP_204_NO_CONTENT,
    summary="Delete a label"
)
def delete_label(label_id: int):
    """Delete a label and all its children (cascade delete)."""
    try:
        with get_db() as conn:
            deleted = LabelCRUD.delete(conn, label_id)
            if not deleted:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Label with id {label_id} not found"
                )
            return None
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting label {label_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to delete label"
        )


# --- Feedback Sentiment Routes ---

async def call_sentiment_service(text: str) -> dict:
    """Call the sentiment analysis service to classify text."""
    # Kiá»ƒm tra xem cÃ³ Ä‘ang training embedding khÃ´ng
    if is_training_in_progress("embedding"):
        logger.warning("âš ï¸  Äang training embedding model - sentiment service cÃ³ thá»ƒ bá»‹ cháº­m hoáº·c khÃ´ng kháº£ dá»¥ng")
    
    # Kiá»ƒm tra xem cÃ³ Ä‘ang training sentiment khÃ´ng
    if is_training_in_progress("sentiment"):
        logger.warning("ðŸ”„ Äang training sentiment model - sentiment service cÃ³ thá»ƒ khÃ´ng kháº£ dá»¥ng, yÃªu cáº§u sáº½ pháº£i chá»")
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{settings.sentiment_service_url}/classify",
                json={"text": text}
            )
            response.raise_for_status()
            return response.json()
    except httpx.HTTPError as e:
        logger.error(f"Error calling sentiment service: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Sentiment analysis service is unavailable"
        )
    except Exception as e:
        logger.error(f"Unexpected error calling sentiment service: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to analyze sentiment"
        )


async def call_embedding_service(text: str) -> list:
    """Call the embedding service to get text embedding."""
    # Kiá»ƒm tra xem cÃ³ Ä‘ang training sentiment khÃ´ng
    if is_training_in_progress("sentiment"):
        logger.warning("âš ï¸  Äang training sentiment model - embedding service cÃ³ thá»ƒ bá»‹ cháº­m hoáº·c khÃ´ng kháº£ dá»¥ng")
    
    # Kiá»ƒm tra xem cÃ³ Ä‘ang training embedding khÃ´ng
    if is_training_in_progress("embedding"):
        logger.warning("ðŸ”„ Äang training embedding model - embedding service cÃ³ thá»ƒ khÃ´ng kháº£ dá»¥ng, yÃªu cáº§u sáº½ pháº£i chá»")
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{settings.embedding_service_url}/encode",
                json={"text": text}
            )
            response.raise_for_status()
            result = response.json()
            return result.get("embedding", [])
    except httpx.HTTPError as e:
        logger.error(f"Error calling embedding service: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Embedding service is unavailable"
        )
    except Exception as e:
        logger.error(f"Unexpected error calling embedding service: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to get embedding"
        )


async def _classify_intent_for_feedback(
    feedback_text: str,
    feedback_id: Optional[UUID] = None
) -> Optional[Dict[str, Any]]:
    """
    Helper function to classify intent for a feedback.
    Returns dict with level1_id, level2_id, level3_id if successful, None otherwise.
    """
    try:
        # Step 1: Get embedding for feedback
        feedback_embedding = await call_embedding_service(feedback_text)
        
        if not feedback_embedding:
            logger.warning(f"Failed to get embedding for feedback {feedback_id or 'new'}")
            return None
        
        # Step 2: Get top 10 intent candidates
        with get_db() as conn:
            intent_candidates = FeedbackIntentCRUD.get_top_intents(
                conn,
                feedback_embedding,
                limit=10,
                top_level1=5,
                top_level2_total=15,
                top_level3_total=50
            )
            
            if not intent_candidates:
                logger.warning(f"No intent candidates found for feedback {feedback_id or 'new'}")
                return None
            
            # Step 3: Use Gemini to select best intent from top 10
            try:
                gemini_service = get_gemini_service()
                selected_intent = gemini_service.select_best_intent(
                    feedback_text,
                    intent_candidates
                )
                if selected_intent:
                    return {
                        'level1_id': selected_intent['level1']['id'],
                        'level2_id': selected_intent['level2']['id'],
                        'level3_id': selected_intent['level3']['id']
                    }
            except Exception as e:
                logger.warning(f"Gemini service error for feedback {feedback_id or 'new'}: {e}")
                return None
        
        return None
    except Exception as e:
        logger.error(f"Error classifying intent for feedback {feedback_id or 'new'}: {e}", exc_info=True)
        return None


async def _reprocess_feedbacks_after_label_update(
    feedback_ids: List[UUID],
) -> List[dict]:
    """Re-run intent prediction pipeline for impacted feedbacks."""
    results: List[dict] = []
    if not feedback_ids:
        return results

    try:
        gemini_service = get_gemini_service()
    except Exception as exc:  # pragma: no cover - initialization may fail in env
        logger.error("Gemini service unavailable for reprocess: %s", exc, exc_info=True)
        gemini_service = None

    for feedback_id in feedback_ids:
        result = {
            "feedback_id": feedback_id,
            "status": FeedbackReprocessStatus.SKIPPED.value,
            "message": None,
        }

        try:
            with get_db() as conn:
                feedback = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
        except Exception as exc:
            logger.error("Failed to load feedback %s: %s", feedback_id, exc, exc_info=True)
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "KhÃ´ng Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u feedback"
            results.append(result)
            continue

        if not feedback:
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "Feedback khÃ´ng tá»“n táº¡i"
            results.append(result)
            continue

        try:
            embedding = await call_embedding_service(feedback["feedback_text"])
        except HTTPException as exc:
            logger.error(
                "Embedding service error (feedback %s): %s",
                feedback_id,
                exc.detail,
            )
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = f"Lá»—i embedding: {exc.detail}"
            results.append(result)
            continue
        except Exception as exc:
            logger.error(
                "Unexpected embedding error (feedback %s): %s",
                feedback_id,
                exc,
                exc_info=True,
            )
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "Lá»—i báº¥t ngá» khi gá»i embedding service"
            results.append(result)
            continue

        if not embedding:
            result["status"] = FeedbackReprocessStatus.SKIPPED.value
            result["message"] = "Embedding rá»—ng"
            results.append(result)
            continue

        try:
            with get_db() as conn:
                intent_candidates = FeedbackIntentCRUD.get_top_intents(
                    conn,
                    embedding,
                    limit=10,
                    top_level1=5,
                    top_level2_total=15,
                    top_level3_total=50,
                )
        except Exception as exc:
            logger.error(
                "Failed to compute intent candidates (feedback %s): %s",
                feedback_id,
                exc,
                exc_info=True,
            )
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "KhÃ´ng tÃ­nh Ä‘Æ°á»£c intent candidates"
            results.append(result)
            continue

        if not intent_candidates:
            result["status"] = FeedbackReprocessStatus.SKIPPED.value
            result["message"] = "KhÃ´ng tÃ¬m tháº¥y intent phÃ¹ há»£p"
            results.append(result)
            continue

        selected_intent = None
        if gemini_service:
            try:
                selected_intent = gemini_service.select_best_intent(
                    feedback["feedback_text"],
                    intent_candidates
                )
            except Exception as exc:  # pragma: no cover - external dependency
                logger.error(
                    "Gemini selection error (feedback %s): %s",
                    feedback_id,
                    exc,
                    exc_info=True,
                )
        else:
            logger.warning(
                "Gemini service unavailable; skipping intent selection for feedback %s",
                feedback_id,
            )

        if not selected_intent:
            result["status"] = FeedbackReprocessStatus.SKIPPED.value
            result["message"] = "Gemini khÃ´ng chá»n Ä‘Æ°á»£c intent"
            results.append(result)
            continue

        update_payload = FeedbackSentimentUpdate(
            level1_id=selected_intent["level1"]["id"],
            level2_id=selected_intent["level2"]["id"],
            level3_id=selected_intent["level3"]["id"],
            is_model_confirmed=False,
        )

        try:
            with get_db() as conn:
                updated_feedback = FeedbackSentimentCRUD.update(conn, feedback_id, update_payload)
        except ValueError as exc:
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = str(exc)
            results.append(result)
            continue
        except Exception as exc:
            logger.error(
                "Failed to update feedback %s after reprocess: %s",
                feedback_id,
                exc,
                exc_info=True,
            )
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "KhÃ´ng cáº­p nháº­t Ä‘Æ°á»£c feedback"
            results.append(result)
            continue

        if not updated_feedback:
            result["status"] = FeedbackReprocessStatus.FAILED.value
            result["message"] = "Feedback khÃ´ng tá»“n táº¡i khi cáº­p nháº­t"
            results.append(result)
            continue

        try:
            manager = get_training_manager()
        except RuntimeError:
            manager = None
        except Exception as exc:  # pragma: no cover - defensive
            logger.error("KhÃ´ng láº¥y Ä‘Æ°á»£c training manager: %s", exc)
            manager = None
        if manager:
            await manager.record_relabel_async("intent", updated_feedback)

        result["status"] = FeedbackReprocessStatus.UPDATED.value
        result["message"] = (
            f"Intent má»›i: {selected_intent['level1']['name']} â†’ "
            f"{selected_intent['level2']['name']} â†’ {selected_intent['level3']['name']}"
        )
        logger.info(
            "Reprocessed feedback %s with new intent (%s, %s, %s)",
            feedback_id,
            selected_intent["level1"]["id"],
            selected_intent["level2"]["id"],
            selected_intent["level3"]["id"],
        )
        results.append(result)

    return results


@router.post(
    "/feedbacks",
    response_model=FeedbackSentimentResponse,
    status_code=status.HTTP_201_CREATED,
    summary="Submit feedback and analyze sentiment + intent"
)
async def create_feedback_sentiment(feedback_data: FeedbackSentimentCreate):
    """
    Submit customer feedback and get:
    1. Sentiment analysis (positive/negative/neutral)
    2. Intent classification using Gemini AI (level 1, 2, 3 labels)
    """
    try:
        # Step 1: Call sentiment service
        logger.info(f"Analyzing sentiment for feedback: {feedback_data.feedback_text[:50]}...")
        sentiment_result = await call_sentiment_service(feedback_data.feedback_text)
        
        sentiment_label = sentiment_result.get("label")
        confidence_score = sentiment_result.get("score")
        
        if not sentiment_label or confidence_score is None:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Invalid response from sentiment service"
            )
        
        # Step 2: Get embedding for feedback
        logger.info("Getting embedding for feedback...")
        feedback_embedding = await call_embedding_service(feedback_data.feedback_text)
        
        if not feedback_embedding:
            logger.warning("Failed to get embedding, saving feedback without intent")
            with get_db() as conn:
                feedback = FeedbackSentimentCRUD.create(
                    conn, feedback_data, sentiment_label, confidence_score,
                    is_model_confirmed=False
                )
                # Thá»­ tá»± Ä‘á»™ng phÃ¢n loáº¡i láº¡i sau khi lÆ°u
                try:
                    intent_result = await _classify_intent_for_feedback(feedback_data.feedback_text, feedback['id'])
                    if intent_result:
                        update_data = FeedbackSentimentUpdate(
                            level1_id=intent_result['level1_id'],
                            level2_id=intent_result['level2_id'],
                            level3_id=intent_result['level3_id'],
                            is_model_confirmed=False
                        )
                        feedback = FeedbackSentimentCRUD.update(conn, feedback['id'], update_data)
                        if feedback:
                            return feedback
                except Exception as e:
                    logger.warning(f"Failed to auto-classify intent after save: {e}")
                return feedback
        
        # Step 3: Get top 10 intent candidates (5 L1 â†’ 15 L2 â†’ 50 L3 â†’ 10 best)
        logger.info("Calculating top 10 intent candidates...")
        with get_db() as conn:
            intent_candidates = FeedbackIntentCRUD.get_top_intents(
                conn,
                feedback_embedding,
                limit=10,
                top_level1=5,
                top_level2_total=15,
                top_level3_total=50
            )
        
        if not intent_candidates:
            logger.warning("No intent candidates found, saving feedback without intent")
            with get_db() as conn:
                feedback = FeedbackSentimentCRUD.create(
                    conn, feedback_data, sentiment_label, confidence_score,
                    is_model_confirmed=False
                )
                return feedback
        
        # Step 4: Use Gemini to select best intent from top 10
        logger.info(f"Calling Gemini to select best intent from {len(intent_candidates)} candidates...")
        try:
            gemini_service = get_gemini_service()
            selected_intent = gemini_service.select_best_intent(
                feedback_data.feedback_text,
                intent_candidates
            )
        except Exception as e:
            logger.error(f"Gemini service error: {e}, continuing without intent")
            selected_intent = None
        
        # Step 5: Save to database with selected intent
        with get_db() as conn:
            if selected_intent:
                feedback = FeedbackSentimentCRUD.create(
                    conn,
                    feedback_data,
                    sentiment_label,
                    confidence_score,
                    level1_id=selected_intent['level1']['id'],
                    level2_id=selected_intent['level2']['id'],
                    level3_id=selected_intent['level3']['id'],
                    is_model_confirmed=False  # Tá»± Ä‘á»™ng phÃ¢n loáº¡i -> chá» xÃ¡c nháº­n
                )
                logger.info(f"Feedback saved with intent: {selected_intent['level1']['name']} â†’ "
                          f"{selected_intent['level2']['name']} â†’ {selected_intent['level3']['name']}")
            else:
                feedback = FeedbackSentimentCRUD.create(
                    conn, feedback_data, sentiment_label, confidence_score,
                    is_model_confirmed=False
                )
                logger.warning("Feedback saved without intent (Gemini failed)")
            
            return feedback
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating feedback sentiment: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to create feedback"
        )


@router.put(
    "/feedbacks/{feedback_id}",
    response_model=FeedbackSentimentResponse,
    summary="Update sentiment or intent labels for a feedback"
)
def update_feedback_sentiment(feedback_id: UUID, update_data: FeedbackSentimentUpdate):
    """Manually update sentiment label and/or intent hierarchy for an existing feedback.
    
    Khi sá»­a báº±ng tay qua API PUT, tá»± Ä‘á»™ng set is_model_confirmed = True (Ä‘Ã£ xÃ¡c nháº­n).
    """
    try:
        with get_db() as conn:
            existing = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
            if not existing:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
            
            # Náº¿u user sá»­a báº±ng tay vÃ  cÃ³ thay Ä‘á»•i sentiment hoáº·c intent
            # nhÆ°ng khÃ´ng chá»‰ Ä‘á»‹nh is_model_confirmed, thÃ¬ máº·c Ä‘á»‹nh = True (Ä‘Ã£ xÃ¡c nháº­n)
            update_dict = update_data.model_dump(exclude_unset=True)
            has_sentiment_change = "sentiment_label" in update_dict
            has_intent_change = any(key in update_dict for key in ["level1_id", "level2_id", "level3_id"])
            
            if (has_sentiment_change or has_intent_change) and "is_model_confirmed" not in update_dict:
                # Sá»­a báº±ng tay qua API -> tá»± Ä‘á»™ng xÃ¡c nháº­n
                update_data.is_model_confirmed = True
            
            updated_feedback = FeedbackSentimentCRUD.update(conn, feedback_id, update_data)
            if not updated_feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
        return updated_feedback
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating feedback {feedback_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to update feedback"
        )


@router.post(
    "/feedbacks/{feedback_id}/confirm",
    response_model=FeedbackSentimentResponse,
    summary="Confirm model prediction for a feedback"
)
def confirm_feedback_sentiment(feedback_id: UUID):
    """ÄÃ¡nh dáº¥u feedback Ä‘Ã£ Ä‘Æ°á»£c ngÆ°á»i dÃ¹ng xÃ¡c nháº­n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Ãºng."""
    try:
        with get_db() as conn:
            existing = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
            payload = FeedbackSentimentUpdate(is_model_confirmed=True)
            updated_feedback = FeedbackSentimentCRUD.update(conn, feedback_id, payload)
            if not updated_feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
        return updated_feedback
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error confirming feedback {feedback_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to confirm feedback"
        )


@router.get(
    "/feedbacks",
    response_model=FeedbackSentimentListResponse,
    summary="Get all feedback sentiments with filters"
)
def get_feedback_sentiments(
    sentiment_label: Optional[SentimentLabel] = Query(None, description="Filter by sentiment label"),
    feedback_source: Optional[FeedbackSource] = Query(None, description="Filter by feedback source"),
    skip: int = Query(0, ge=0, description="Number of records to skip"),
    limit: int = Query(100, ge=1, le=1000, description="Maximum number of records"),
):
    """Get all feedback sentiments with optional filters."""
    try:
        with get_db() as conn:
            # Convert enums to values for database query
            label_value = sentiment_label.value if sentiment_label else None
            source_value = feedback_source.value if feedback_source else None
            
            feedbacks = FeedbackSentimentCRUD.get_all(
                conn,
                sentiment_label=label_value,
                feedback_source=source_value,
                skip=skip,
                limit=limit
            )
            total = FeedbackSentimentCRUD.count(
                conn,
                sentiment_label=label_value,
                feedback_source=source_value
            )
            
            return FeedbackSentimentListResponse(
                feedbacks=feedbacks,
                total=total,
                sentiment_label=sentiment_label,
                feedback_source=feedback_source
            )
    except Exception as e:
        logger.error(f"Error getting feedback sentiments: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve feedbacks"
        )


@router.get(
    "/feedbacks/{feedback_id}",
    response_model=FeedbackSentimentResponse,
    summary="Get feedback sentiment by ID"
)
def get_feedback_sentiment(feedback_id: UUID):
    """Get a specific feedback sentiment by ID."""
    try:
        with get_db() as conn:
            feedback = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
            if not feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
            return feedback
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting feedback {feedback_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve feedback"
        )


@router.post(
    "/feedbacks/import",
    response_model=FeedbackImportResponse,
    summary="Import feedback data from Excel file"
)
async def import_feedbacks_from_excel(file: UploadFile = File(...)):
    """Import feedback sentiments from an Excel file."""
    if not file.filename or not file.filename.lower().endswith(".xlsx"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Chá»‰ há»— trá»£ import file Excel Ä‘á»‹nh dáº¡ng .xlsx"
        )

    content = await file.read()
    if not content:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File Excel khÃ´ng cÃ³ dá»¯ liá»‡u"
        )

    try:
        workbook = load_workbook(filename=BytesIO(content), data_only=True)
    except Exception as exc:
        logger.error(f"Failed to read Excel file during import: {exc}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="KhÃ´ng thá»ƒ Ä‘á»c file Excel. Vui lÃ²ng kiá»ƒm tra Ä‘á»‹nh dáº¡ng vÃ  ná»™i dung."
        )

    sheet = workbook.active
    header_row = next(sheet.iter_rows(min_row=1, max_row=1, values_only=True), None)
    if not header_row:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File Excel khÃ´ng cÃ³ dÃ²ng header"
        )

    normalized_headers = [
        str(cell).strip().lower() if cell is not None else ""
        for cell in header_row
    ]
    required_headers = ["content", "sentiment", "level1", "level2", "level3"]
    missing_columns = [col for col in required_headers if col not in normalized_headers]
    if missing_columns:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"File Excel thiáº¿u cÃ¡c cá»™t báº¯t buá»™c: {', '.join(missing_columns)}"
        )

    total_rows = max(sheet.max_row - 1, 0)
    workbook.close()

    task_id = str(uuid4())
    asyncio.create_task(
        _process_feedback_import_file(
            file_bytes=content,
            task_id=task_id,
            original_filename=file.filename,
        )
    )

    return FeedbackImportResponse(
        imported=0,
        failed=0,
        log_file=None,
        queued=total_rows,
        task_id=task_id,
        status="queued",
        message=f"ÄÃ£ Ä‘Æ°a {total_rows} dÃ²ng vÃ o hÃ ng Ä‘á»£i xá»­ lÃ½ ná»n (task_id={task_id})",
    )


@router.post(
    "/feedbacks/import-simple",
    response_model=FeedbackImportResponse,
    summary="Import feedback data from Excel file (simple format: content and source only)"
)
async def import_feedbacks_simple_from_excel(file: UploadFile = File(...)):
    """
    Import feedback sentiments from an Excel file with simple format.
    Required columns: content (ná»™i dung feedback)
    Optional columns: source (nguá»“n feedback, default: 'web')
    The system will automatically analyze sentiment and intent for each feedback.
    """
    if not file.filename or not file.filename.lower().endswith(".xlsx"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Chá»‰ há»— trá»£ import file Excel Ä‘á»‹nh dáº¡ng .xlsx"
        )

    content = await file.read()
    if not content:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File Excel khÃ´ng cÃ³ dá»¯ liá»‡u"
        )

    try:
        workbook = load_workbook(filename=BytesIO(content), data_only=True)
    except Exception as exc:
        logger.error(f"Failed to read Excel file during import: {exc}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="KhÃ´ng thá»ƒ Ä‘á»c file Excel. Vui lÃ²ng kiá»ƒm tra Ä‘á»‹nh dáº¡ng vÃ  ná»™i dung."
        )

    sheet = workbook.active
    header_row = next(sheet.iter_rows(min_row=1, max_row=1, values_only=True), None)
    if not header_row:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File Excel khÃ´ng cÃ³ dÃ²ng header"
        )

    normalized_headers = [
        str(cell).strip().lower() if cell is not None else ""
        for cell in header_row
    ]

    if not any(header in ["content", "ná»™i dung", "feedback", "feedback_text", "text"] for header in normalized_headers):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="File Excel pháº£i cÃ³ cá»™t 'content'"
        )

    total_rows = max(sheet.max_row - 1, 0)
    workbook.close()

    task_id = str(uuid4())
    asyncio.create_task(
        _process_feedback_import_simple_file(
            file_bytes=content,
            task_id=task_id,
            original_filename=file.filename,
        )
    )

    return FeedbackImportResponse(
        imported=0,
        failed=0,
        log_file=None,
        queued=total_rows,
        task_id=task_id,
        status="queued",
        message=f"ÄÃ£ Ä‘Æ°a {total_rows} dÃ²ng vÃ o hÃ ng Ä‘á»£i xá»­ lÃ½ ná»n (task_id={task_id})",
    )


def _normalize_cell(value) -> str:
    if value is None:
        return ""
    return str(value).strip()


def _resolve_feedback_source(value: str) -> FeedbackSource:
    normalized = value.lower()
    mapping = {
        "web": FeedbackSource.WEB,
        "app": FeedbackSource.APP,
        "map": FeedbackSource.MAP,
        "form kháº£o sÃ¡t": FeedbackSource.SURVEY_FORM,
        "survey": FeedbackSource.SURVEY_FORM,
        "tá»•ng Ä‘Ã i": FeedbackSource.CALL_CENTER,
        "call center": FeedbackSource.CALL_CENTER,
    }
    return mapping.get(normalized, FeedbackSource.WEB)


def _write_import_error_log(error_rows: List[Dict[str, Any]], filename_prefix: str) -> Optional[str]:
    if not error_rows:
        return None

    log_dir = Path(__file__).resolve().parent / "logs" / "feedback_import"
    try:
        log_dir.mkdir(parents=True, exist_ok=True)
        os.chmod(log_dir, 0o777)
    except (PermissionError, OSError) as exc:
        logger.warning(f"KhÃ´ng thá»ƒ táº¡o thÆ° má»¥c logs: {exc}. DÃ¹ng thÆ° má»¥c táº¡m.")
        import tempfile
        log_dir = Path(tempfile.gettempdir()) / "feedback_import_logs"
        log_dir.mkdir(parents=True, exist_ok=True)

    log_file_path = log_dir / f"{filename_prefix}_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.csv"
    with log_file_path.open("w", newline="", encoding="utf-8") as csvfile:
        fieldnames = ["row_index", "content", "sentiment", "level1", "level2", "level3", "errors"]
        if "sentiment" not in error_rows[0]:
            fieldnames = ["row_index", "content", "errors"]

        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for row in error_rows:
            writer.writerow(row)

    try:
        return str(log_file_path.relative_to(Path(__file__).resolve().parent))
    except ValueError:
        return str(log_file_path)


async def _process_feedback_import_file(file_bytes: bytes, task_id: str, original_filename: Optional[str] = None):
    logger.info(f"[ImportTask {task_id}] Báº¯t Ä‘áº§u xá»­ lÃ½ import Ä‘áº§y Ä‘á»§ cho file {original_filename or 'upload.xlsx'}")
    try:
        workbook = load_workbook(filename=BytesIO(file_bytes), data_only=True)
    except Exception as exc:
        logger.error(f"[ImportTask {task_id}] KhÃ´ng thá»ƒ Ä‘á»c file Excel: {exc}")
        return

    sheet = workbook.active
    header_row = next(sheet.iter_rows(min_row=1, max_row=1, values_only=True), None)
    if not header_row:
        logger.error(f"[ImportTask {task_id}] File Excel khÃ´ng cÃ³ dÃ²ng header")
        return

    normalized_headers = [_normalize_cell(cell).lower() for cell in header_row]
    required_headers = ["content", "sentiment", "level1", "level2", "level3"]
    missing_columns = [col for col in required_headers if col not in normalized_headers]
    if missing_columns:
        logger.error(f"[ImportTask {task_id}] File thiáº¿u cá»™t: {', '.join(missing_columns)}")
        return

    header_index = {name: idx for idx, name in enumerate(normalized_headers)}

    def _get_value(row_values, column: str):
        idx = header_index[column]
        if idx >= len(row_values):
            return None
        return row_values[idx]

    inserted = 0
    error_rows: List[Dict[str, Any]] = []

    with get_db() as conn:
        labels = LabelCRUD.get_all(conn, skip=0, limit=100000)

    labels_by_level = {1: {}, 2: {}, 3: {}}
    for label in labels:
        label_name = _normalize_cell(label.get("name"))
        if label_name:
            labels_by_level[label["level"]][label_name.lower()] = label

    for row_idx, row in enumerate(sheet.iter_rows(min_row=2, values_only=True), start=2):
        row_values = list(row) if row else []
        if len(row_values) < len(normalized_headers):
            row_values.extend([None] * (len(normalized_headers) - len(row_values)))

        if all(_normalize_cell(row_values[header_index[col]]) == "" for col in required_headers):
            continue

        content_value = _normalize_cell(_get_value(row_values, "content"))
        sentiment_value = _normalize_cell(_get_value(row_values, "sentiment"))
        level1_value = _normalize_cell(_get_value(row_values, "level1"))
        level2_value = _normalize_cell(_get_value(row_values, "level2"))
        level3_value = _normalize_cell(_get_value(row_values, "level3"))

        if not content_value:
            error_rows.append(
                {
                    "row_index": row_idx,
                    "content": content_value,
                    "sentiment": sentiment_value,
                    "level1": level1_value,
                    "level2": level2_value,
                    "level3": level3_value,
                    "errors": "Thiáº¿u ná»™i dung feedback",
                }
            )
            continue

        row_errors = []
        sentiment_enum = None
        if sentiment_value:
            try:
                sentiment_enum = SentimentLabel(sentiment_value.upper())
            except ValueError:
                row_errors.append(f"Sentiment khÃ´ng há»£p lá»‡: {sentiment_value}")
        else:
            row_errors.append("Thiáº¿u sentiment")

        level1_label = labels_by_level[1].get(level1_value.lower()) if level1_value else None
        level2_label = labels_by_level[2].get(level2_value.lower()) if level2_value else None
        level3_label = labels_by_level[3].get(level3_value.lower()) if level3_value else None

        if level1_value and not level1_label:
            row_errors.append(f"Level1 '{level1_value}' khÃ´ng tá»“n táº¡i")
        if level2_value:
            if not level1_label:
                row_errors.append("Level2 yÃªu cáº§u Level1 há»£p lá»‡")
            elif not level2_label:
                row_errors.append(f"Level2 '{level2_value}' khÃ´ng tá»“n táº¡i")
            elif level2_label["parent_id"] != level1_label["id"]:
                row_errors.append(f"Level2 '{level2_value}' khÃ´ng thuá»™c Level1 '{level1_label['name']}'")
        if level3_value:
            if not level2_label:
                row_errors.append("Level3 yÃªu cáº§u Level2 há»£p lá»‡")
            elif not level3_label:
                row_errors.append(f"Level3 '{level3_value}' khÃ´ng tá»“n táº¡i")
            elif level3_label["parent_id"] != level2_label["id"]:
                row_errors.append(f"Level3 '{level3_value}' khÃ´ng thuá»™c Level2 '{level2_label['name']}'")

        sentiment_label_value = sentiment_enum.value if sentiment_enum else None
        confidence_score = 1.0
        if not sentiment_label_value:
            try:
                sentiment_result = await call_sentiment_service(content_value)
                sentiment_label_value = sentiment_result.get("label") or SentimentLabel.NEUTRAL.value
                confidence_score = sentiment_result.get("score", 1.0)
            except Exception as exc:
                row_errors.append(f"KhÃ´ng thá»ƒ phÃ¢n loáº¡i sentiment: {exc}")
                sentiment_label_value = SentimentLabel.NEUTRAL.value

        level1_id = level1_label["id"] if level1_label else None
        level2_id = level2_label["id"] if level2_label else None
        level3_id = level3_label["id"] if level3_label else None
        has_all_labels = level1_id and level2_id and level3_id
        has_label_errors = any("level" in err.lower() for err in row_errors)
        has_valid_sentiment = sentiment_enum is not None

        if not (has_all_labels and not has_label_errors and has_valid_sentiment):
            intent_result = await _classify_intent_for_feedback(content_value)
            if intent_result:
                level1_id = intent_result["level1_id"]
                level2_id = intent_result["level2_id"]
                level3_id = intent_result["level3_id"]
            else:
                level1_id = level2_id = level3_id = None
            is_model_confirmed = False
        else:
            is_model_confirmed = True

        feedback_data = FeedbackSentimentCreate(
            feedback_text=content_value,
            feedback_source=FeedbackSource.WEB,
        )

        try:
            with get_db() as conn:
                FeedbackSentimentCRUD.create(
                    conn,
                    feedback_data,
                    sentiment_label_value,
                    confidence_score=confidence_score,
                    level1_id=level1_id,
                    level2_id=level2_id,
                    level3_id=level3_id,
                    is_model_confirmed=is_model_confirmed,
                )
            inserted += 1
        except Exception as exc:
            row_errors.append(f"Lá»—i lÆ°u DB: {exc}")
            logger.error(f"[ImportTask {task_id}] Lá»—i lÆ°u row {row_idx}: {exc}", exc_info=True)

        if row_errors:
            error_rows.append(
                {
                    "row_index": row_idx,
                    "content": content_value,
                    "sentiment": sentiment_value,
                    "level1": level1_value,
                    "level2": level2_value,
                    "level3": level3_value,
                    "errors": " | ".join(row_errors),
                }
            )

    workbook.close()
    log_file = _write_import_error_log(error_rows, filename_prefix=f"errors_full_{task_id}")
    logger.info(
        f"[ImportTask {task_id}] HoÃ n thÃ nh import Ä‘áº§y Ä‘á»§: inserted={inserted}, errors={len(error_rows)}, log={log_file}"
    )


async def _process_feedback_import_simple_file(file_bytes: bytes, task_id: str, original_filename: Optional[str] = None):
    logger.info(f"[ImportTask {task_id}] Báº¯t Ä‘áº§u xá»­ lÃ½ import Ä‘Æ¡n giáº£n cho file {original_filename or 'upload.xlsx'}")
    try:
        workbook = load_workbook(filename=BytesIO(file_bytes), data_only=True)
    except Exception as exc:
        logger.error(f"[ImportTask {task_id}] KhÃ´ng thá»ƒ Ä‘á»c file Excel: {exc}")
        return

    sheet = workbook.active
    header_row = next(sheet.iter_rows(min_row=1, max_row=1, values_only=True), None)
    if not header_row:
        logger.error(f"[ImportTask {task_id}] File Excel khÃ´ng cÃ³ dÃ²ng header")
        return

    normalized_headers = [_normalize_cell(cell).lower() for cell in header_row]
    content_col_idx = None
    source_col_idx = None
    for idx, header in enumerate(normalized_headers):
        if header in ["content", "ná»™i dung", "feedback", "feedback_text", "text"]:
            content_col_idx = idx
        elif header in ["source", "nguá»“n", "feedback_source"]:
            source_col_idx = idx

    if content_col_idx is None:
        logger.error(f"[ImportTask {task_id}] Thiáº¿u cá»™t content")
        return

    inserted = 0
    error_rows: List[Dict[str, Any]] = []

    for row_idx, row in enumerate(sheet.iter_rows(min_row=2, values_only=True), start=2):
        row_values = list(row) if row else []
        if content_col_idx >= len(row_values):
            continue

        content_value = _normalize_cell(row_values[content_col_idx])
        if not content_value:
            error_rows.append(
                {
                    "row_index": row_idx,
                    "content": content_value,
                    "errors": "Thiáº¿u ná»™i dung feedback",
                }
            )
            continue

        source_value = "web"
        if source_col_idx is not None and source_col_idx < len(row_values):
            raw_source = _normalize_cell(row_values[source_col_idx])
            if raw_source:
                source_value = raw_source.lower()

        feedback_source = _resolve_feedback_source(source_value)
        feedback_data = FeedbackSentimentCreate(
            feedback_text=content_value,
            feedback_source=feedback_source,
        )

        try:
            sentiment_result = await call_sentiment_service(content_value)
            sentiment_label = sentiment_result.get("label") or SentimentLabel.NEUTRAL.value
            confidence_score = sentiment_result.get("score", 1.0)

            intent_result = await _classify_intent_for_feedback(content_value)
            if intent_result:
                level1_id = intent_result["level1_id"]
                level2_id = intent_result["level2_id"]
                level3_id = intent_result["level3_id"]
            else:
                level1_id = level2_id = level3_id = None

            with get_db() as conn:
                FeedbackSentimentCRUD.create(
                    conn,
                    feedback_data,
                    sentiment_label,
                    confidence_score=confidence_score,
                    level1_id=level1_id,
                    level2_id=level2_id,
                    level3_id=level3_id,
                    is_model_confirmed=False,
                )
            inserted += 1
        except Exception as exc:
            logger.error(f"[ImportTask {task_id}] Lá»—i xá»­ lÃ½ row {row_idx}: {exc}", exc_info=True)
            error_rows.append(
                {
                    "row_index": row_idx,
                    "content": content_value,
                    "errors": str(exc),
                }
            )

    workbook.close()
    log_file = _write_import_error_log(error_rows, filename_prefix=f"errors_simple_{task_id}")
    logger.info(
        f"[ImportTask {task_id}] HoÃ n thÃ nh import Ä‘Æ¡n giáº£n: inserted={inserted}, errors={len(error_rows)}, log={log_file}"
    )


# --- Intent Analysis Routes ---

@router.post(
    "/feedbacks/{feedback_id}/intents",
    response_model=FeedbackIntentResponse,
    status_code=status.HTTP_200_OK,
    summary="Analyze feedback intents"
)
async def analyze_feedback_intents(feedback_id: UUID):
    """
    Analyze feedback and return top 10 intent triplets based on cosine similarity.
    This endpoint calculates or retrieves cached intent analysis results.
    """
    try:
        with get_db() as conn:
            # Check if feedback exists
            feedback = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
            if not feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
            
            # Try to get cached intents first (top 50)
            cached_intents = FeedbackIntentCRUD.get_cached_intents(conn, feedback_id, limit=50)
            
            if cached_intents:
                logger.info(f"Returning cached intents for feedback {feedback_id}")
                return FeedbackIntentResponse(
                    feedback_id=feedback_id,
                    intents=[IntentTriplet(**intent) for intent in cached_intents],
                    total_intents=len(cached_intents)
                )
            
            # Calculate new intents
            logger.info(f"Calculating new intents for feedback {feedback_id}")
            
            # Get embedding for feedback text
            feedback_embedding = await call_embedding_service(feedback['feedback_text'])
            
            if not feedback_embedding:
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail="Failed to get feedback embedding"
                )
            
            # Calculate top intents using hierarchical approach
            # Top 5 level1 â†’ top 20 level2 â†’ top 50 triplets
            intents = FeedbackIntentCRUD.get_top_intents(
                conn, 
                feedback_embedding, 
                limit=50,
                top_level1=5,
                top_level2_per_level1=4,
                top_level3_per_level2=3
            )
            
            if not intents:
                logger.warning(f"No intents found for feedback {feedback_id}")
                return FeedbackIntentResponse(
                    feedback_id=feedback_id,
                    intents=[],
                    total_intents=0
                )
            
            # Save intents to cache
            FeedbackIntentCRUD.save_intents(conn, feedback_id, intents)
            
            return FeedbackIntentResponse(
                feedback_id=feedback_id,
                intents=[IntentTriplet(**intent) for intent in intents],
                total_intents=len(intents)
            )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error analyzing intents for feedback {feedback_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to analyze feedback intents"
        )


@router.post(
    "/feedbacks/auto-classify-intents",
    summary="Tá»± Ä‘á»™ng phÃ¢n loáº¡i intent cho cÃ¡c feedback chÆ°a cÃ³ intent"
)
async def auto_classify_feedbacks_without_intents():
    """
    Tá»± Ä‘á»™ng phÃ¢n loáº¡i intent cho táº¥t cáº£ feedback chÆ°a cÃ³ intent (level1_id IS NULL).
    QuÃ©t toÃ n bá»™ database vÃ  phÃ¢n loáº¡i intent cho cÃ¡c feedback chÆ°a Ä‘Æ°á»£c phÃ¢n loáº¡i.
    CÃ¡c feedback sau khi Ä‘Æ°á»£c phÃ¢n loáº¡i sáº½ cÃ³ is_model_confirmed = False (chá» xÃ¡c nháº­n).
    """
    try:
        with get_db() as conn:
            from database import execute_query
            
            # Láº¥y táº¥t cáº£ feedback chÆ°a cÃ³ intent (level1_id, level2_id, level3_id Ä‘á»u NULL)
            results = execute_query(
                conn,
                """
                SELECT id, feedback_text 
                FROM feedback_sentiments 
                WHERE level1_id IS NULL 
                  AND level2_id IS NULL 
                  AND level3_id IS NULL
                ORDER BY created_at DESC
                """,
                fetch="all"
            )
            
            feedbacks = [dict(row) for row in results] if results else []
            
            if not feedbacks:
                return {
                    "status": "success",
                    "message": "KhÃ´ng cÃ³ feedback nÃ o cáº§n phÃ¢n loáº¡i",
                    "total": 0,
                    "classified": 0,
                    "failed": 0
                }
            
            # Kiá»ƒm tra xem labels Ä‘Ã£ cÃ³ embeddings chÆ°a
            labels_with_embeddings = LabelCRUD.get_all_with_embeddings(conn)
            has_all_levels = (
                len(labels_with_embeddings.get(1, [])) > 0 and
                len(labels_with_embeddings.get(2, [])) > 0 and
                len(labels_with_embeddings.get(3, [])) > 0
            )
            
            if not has_all_levels:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Labels chÆ°a cÃ³ embeddings. Vui lÃ²ng cháº¡y endpoint POST /admin/seed-label-embeddings trÆ°á»›c Ä‘á»ƒ seed embeddings cho labels."
                )
            
            logger.info(f"Báº¯t Ä‘áº§u tá»± Ä‘á»™ng phÃ¢n loáº¡i intent cho {len(feedbacks)} feedback")
            
            classified = 0
            failed = 0
            
            for feedback in feedbacks:
                try:
                    feedback_id = feedback['id']
                    feedback_text = feedback['feedback_text']
                    
                    # PhÃ¢n loáº¡i intent
                    intent_result = await _classify_intent_for_feedback(feedback_text, feedback_id)
                    
                    if intent_result:
                        # Cáº­p nháº­t feedback vá»›i intent má»›i, is_model_confirmed = False
                        update_data = FeedbackSentimentUpdate(
                            level1_id=intent_result['level1_id'],
                            level2_id=intent_result['level2_id'],
                            level3_id=intent_result['level3_id'],
                            is_model_confirmed=False
                        )
                        FeedbackSentimentCRUD.update(conn, feedback_id, update_data)
                        classified += 1
                        logger.info(f"ÄÃ£ phÃ¢n loáº¡i intent cho feedback {feedback_id}")
                    else:
                        failed += 1
                        logger.warning(f"KhÃ´ng thá»ƒ phÃ¢n loáº¡i intent cho feedback {feedback_id}")
                        
                except Exception as e:
                    failed += 1
                    logger.error(f"Lá»—i khi phÃ¢n loáº¡i feedback {feedback.get('id')}: {e}", exc_info=True)
            
            return {
                "status": "success",
                "message": f"ÄÃ£ phÃ¢n loáº¡i {classified} feedback, {failed} feedback tháº¥t báº¡i",
                "total": len(feedbacks),
                "classified": classified,
                "failed": failed
            }
    
    except Exception as e:
        logger.error(f"Error auto-classifying feedbacks: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"KhÃ´ng thá»ƒ tá»± Ä‘á»™ng phÃ¢n loáº¡i feedback: {str(e)}"
        )


@router.get(
    "/feedbacks/{feedback_id}/intents",
    response_model=FeedbackIntentResponse,
    summary="Get cached feedback intents"
)
def get_feedback_intents(feedback_id: UUID):
    """Get cached intent analysis results for a feedback."""
    try:
        with get_db() as conn:
            # Check if feedback exists
            feedback = FeedbackSentimentCRUD.get_by_id(conn, feedback_id)
            if not feedback:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Feedback with id {feedback_id} not found"
                )
            
            # Get cached intents (top 50)
            cached_intents = FeedbackIntentCRUD.get_cached_intents(conn, feedback_id, limit=50)
            
            if not cached_intents:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"No intent analysis found for feedback {feedback_id}. Please use POST endpoint to analyze."
                )
            
            return FeedbackIntentResponse(
                feedback_id=feedback_id,
                intents=[IntentTriplet(**intent) for intent in cached_intents],
                total_intents=len(cached_intents)
            )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting intents for feedback {feedback_id}: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve feedback intents"
        )


# --- Admin/Seed Data Routes ---

@router.post(
    "/admin/seed-label-embeddings",
    summary="Seed embeddings for all labels (Admin)"
)
async def seed_label_embeddings():
    """
    Admin endpoint to compute and update embeddings for all labels.
    This should be called after adding new labels or when initializing the system.
    """
    try:
        with get_db() as conn:
            # Get all labels
            all_labels = LabelCRUD.get_all(conn, skip=0, limit=1000)
            
            if not all_labels:
                return {
                    "status": "success",
                    "message": "No labels found to process",
                    "total": 0,
                    "processed": 0,
                    "failed": 0
                }
            
            logger.info(f"Starting to seed embeddings for {len(all_labels)} labels")
            
            processed = 0
            failed = 0
            
            for label in all_labels:
                try:
                    # Create text for embedding
                    text = label['name']
                    if label.get('description'):
                        text = f"{label['name']}. {label['description']}"
                    
                    # Get embedding
                    embedding = await call_embedding_service(text)
                    
                    if not embedding:
                        logger.warning(f"Failed to get embedding for label: {label['name']} (id={label['id']})")
                        failed += 1
                        continue
                    
                    # Update label with embedding
                    LabelCRUD.update_embedding(conn, label['id'], embedding)
                    processed += 1
                    logger.debug(f"Updated embedding for label: {label['name']} (id={label['id']})")
                    
                except Exception as e:
                    logger.error(f"Error processing label {label['id']}: {e}")
                    failed += 1
            
            return {
                "status": "success",
                "message": f"Completed seeding embeddings",
                "total": len(all_labels),
                "processed": processed,
                "failed": failed
            }
    
    except Exception as e:
        logger.error(f"Error in seed_label_embeddings: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to seed label embeddings: {str(e)}"
        )


@router.post(
    "/admin/seed-feedback-intents",
    summary="Seed intents for all feedbacks (Admin)"
)
async def seed_feedback_intents(recompute: bool = False):
    """
    Admin endpoint to compute and cache intents for all feedbacks.
    
    Args:
        recompute: If True, recompute intents for all feedbacks including those with cached results.
                  If False, only compute for feedbacks without cached results.
    """
    try:
        with get_db() as conn:
            # Get feedbacks to process
            if recompute:
                # Get all feedbacks
                from database import execute_query
                results = execute_query(
                    conn,
                    "SELECT id, feedback_text, created_at FROM feedback_sentiments ORDER BY created_at DESC",
                    fetch="all"
                )
                feedbacks = [dict(row) for row in results] if results else []
            else:
                # Get only feedbacks without intents
                from database import execute_query
                results = execute_query(
                    conn,
                    """
                    SELECT DISTINCT fs.id, fs.feedback_text, fs.created_at
                    FROM feedback_sentiments fs
                    LEFT JOIN feedback_intents fi ON fs.id = fi.feedback_id
                    WHERE fi.id IS NULL
                    ORDER BY fs.created_at DESC
                    """,
                    fetch="all"
                )
                feedbacks = [dict(row) for row in results] if results else []
            
            if not feedbacks:
                return {
                    "status": "success",
                    "message": "No feedbacks found to process",
                    "total": 0,
                    "processed": 0,
                    "failed": 0
                }
            
            logger.info(f"Starting to seed intents for {len(feedbacks)} feedbacks")
            
            processed = 0
            failed = 0
            
            for feedback in feedbacks:
                try:
                    feedback_id = feedback['id']
                    feedback_text = feedback['feedback_text']
                    
                    # Get embedding for feedback
                    feedback_embedding = await call_embedding_service(feedback_text)
                    
                    if not feedback_embedding:
                        logger.warning(f"Failed to get embedding for feedback {feedback_id}")
                        failed += 1
                        continue
                    
                    # Calculate top intents using hierarchical approach
                    # Top 5 level1 â†’ top 20 level2 â†’ top 50 triplets
                    intents = FeedbackIntentCRUD.get_top_intents(
                        conn, 
                        feedback_embedding, 
                        limit=50,
                        top_level1=5,
                        top_level2_per_level1=4,
                        top_level3_per_level2=3
                    )
                    
                    if intents:
                        # Save intents to cache
                        FeedbackIntentCRUD.save_intents(conn, feedback_id, intents)
                        processed += 1
                        logger.debug(f"Computed intents for feedback {feedback_id}")
                    else:
                        logger.warning(f"No intents found for feedback {feedback_id}")
                        failed += 1
                    
                except Exception as e:
                    logger.error(f"Error processing feedback {feedback.get('id')}: {e}")
                    failed += 1
            
            return {
                "status": "success",
                "message": f"Completed seeding intents",
                "total": len(feedbacks),
                "processed": processed,
                "failed": failed,
                "recompute": recompute
            }
    
    except Exception as e:
        logger.error(f"Error in seed_feedback_intents: {e}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to seed feedback intents: {str(e)}"
        )
